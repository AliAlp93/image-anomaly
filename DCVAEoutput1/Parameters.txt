alpha=0.00005
beta1=0.6
lr=0.00005
latent_dim=50
epoch=300
-----------------------------------------------------------------------
class Encoder(nn.Module):
    def __init__(self, latent_dim):
        super(Encoder, self).__init__()
        
        
        # build your model here
        # your model should output a predicted mean and a predicted std of the encoding
        # both should be of dim (batch_size, latent_dim)
    
        self.Conv1 = nn.Conv2d(3, 8, 6, stride=3) # 150-6}/3=48  // 49 torch.Size([15, 8, 49, 49])
        self.relu1=nn.ReLU()
        # self.bn1 = nn.BatchNorm1d(8)
        
        self.Conv2 = nn.Conv2d(8, 15, 3 , stride=2) # 48-4}/2= 22  //24 torch.Size([15, 15, 24, 24])
        self.relu2=nn.ReLU()
        # self.bn2 = nn.BatchNorm1d(12)
       
               
        self.Conv3 = nn.Conv2d(15, 30, 2 , stride=2) # 22-2}/2=10  //torch.Size([15, 30, 12, 12])
        self.relu3=nn.ReLU() 
        
        self.Conv4 = nn.Conv2d(30, 50, 2 , stride=2) # 10-2}/2=4  //torch.Size([15, 50, 6, 6])
        self.relu4=nn.ReLU() 
       
        self.Dense1=nn.Linear(50*6*6,1200)
        self.Dense1Act=nn.ReLU()
        
        self.Dense2=nn.Linear(1200,600)
        self.Dense2Act=nn.ReLU() ##nn.LeakyReLU(0.01)
        
        self.Dense3=nn.Linear(600,200)
        self.Dense3Act=nn.ReLU()
        
        self.Dense4=nn.Linear(200,100)
        self.Dense4Act=nn.ReLU()
        
        self.linear_means = nn.Linear(100, latent_dim)
        self.linear_log_var = nn.Linear(100, latent_dim)


-----------------------------------------------------------------------
class Decoder(nn.Module):
    def __init__(self, latent_dim):
        super(Decoder, self).__init__()
        # build your model here
        # your output should be of dim (batch_size, output_dim)
        # you can use tanh() as the activation for the last layer
        # since y coord of airfoils range from -1 to 1
        
        #self.Dense=nn.Linear(latent_dim,24)
        
        self.Dense1=nn.Linear(latent_dim,200) #// torch.Size([15, 50])
        self.Dense1Act=nn.ReLU()
        
        self.Dense2=nn.Linear(200,600)
        self.Dense2Act=nn.ReLU()

        
        self.Dense3=nn.Linear(600,50*4*4) #// torch.Size([15, 50, 4, 4])
        self.Dense3Act=nn.ReLU()
        

# =============================================================================
#   ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0      
#   H out=(Hin−1)×stride[0]−2×padding[0]+dilation[0]×(kernel_size[0]−1)+output_padding[0]+1 
#   H out=(Hin−1)×stride[0]+(kernel_size[0])     
# =============================================================================

        self.Conv4 = nn.ConvTranspose2d(50, 30, 2 , stride=2) # 4-1}*2+2 = 8  torch.Size([15, 30, 8, 8])
        self.relu4=nn.ReLU() 

        self.Conv3 = nn.ConvTranspose2d(30, 15, 3, stride=3) # 8-1)*3+3 = 24 torch.Size([15, 15, 24, 24])
        self.relu3=nn.ReLU() 

        self.Conv2 = nn.ConvTranspose2d(15, 8, 3 , stride=2) # 24-1)*2+ 3 = 49 torch.Size([15, 8, 55, 55])
        self.relu2=nn.ReLU()
        #self.bn2 = nn.BatchNorm1d(12)

        
        self.Conv1 = nn.ConvTranspose2d(8, 3, 6, stride=3) # 49-1)*3+ 6 = 150
        self.relu1=nn.Sigmoid()